{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量（tensor）\n",
    "\n",
    "\n",
    "TensorFlow的基本数据结构\n",
    "\n",
    "+ 按属性而言，张量可分为常量（**constant**）和变量（**Variable**）。常量就是值不会发生变化的量，而变量是开始给定初始值，但是值会发生变化的量。\n",
    "\n",
    "+ 张量在概念上等同于数组，这一点和numpy中的**array**数组类似。可以用来表示数学中的标量（scalar）、向量（vector）、矩阵（matrix）以及多维数组。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow版本:2.1.0\n"
     ]
    }
   ],
   "source": [
    "# 导入tensorflow\n",
    "import tensorflow as tf\n",
    "print('tensorflow版本', tf.__version__, sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于张量，其主要属性包括维度、值和类型(值的类型)，可分别通过张量的 **.shape**、 **.numpy()**和 **d.type**方法获得。对于变量张量，还有名称和是否参与训练的属性，前者可通过 **.name**获得，后者默认是参与训练，也就是**trainable=True**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1024.0, shape=(), dtype=float32)\n",
      "维度: ()\n",
      "值: 1024.0\n",
      "类型: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# 常量\n",
    "ctensor = tf.constant(1024.)\n",
    "print(ctensor)\n",
    "print('维度:', ctensor.shape)\n",
    "print('值:', ctensor.numpy())\n",
    "print('类型:', ctensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=2>\n",
      "维度: ()\n",
      "值: 2\n",
      "类型: <dtype: 'int32'>\n",
      "名称: Variable:0\n",
      "是否参与训练: True\n"
     ]
    }
   ],
   "source": [
    "# 变量\n",
    "vtensor = tf.Variable(2)\n",
    "print(vtensor)\n",
    "print('维度:', vtensor.shape)\n",
    "print('值:', vtensor.numpy())\n",
    "print('类型:', vtensor.dtype)\n",
    "print('名称:', vtensor.name)\n",
    "print('是否参与训练:', vtensor.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，这几个属性也可以在定义张量时直接给出，注意给出的维度应该可以由给出的值转化得到，给出的类型也要符合给出的值的类型，否则会出现错误。并且变量张量设定的维度要和给定的值的维度一样，在实际的机器学习操作中，变量的初始值都是根据需要的维度随机给定的，基本不会涉及这样的维度转换操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3]\n",
      " [3]], shape=(2, 1), dtype=int64)\n",
      "<tf.Variable 'v_0:0' shape=(2,) dtype=int64, numpy=array([3, 3], dtype=int64)>\n"
     ]
    }
   ],
   "source": [
    "ctensor = tf.constant([[[3, 3]]], dtype=tf.int64, shape=(2, 1))\n",
    "print(ctensor)\n",
    "vtensor = tf.Variable([3, 3], dtype=tf.int64, shape=(2,), name='v_0', trainable=False)\n",
    "print(vtensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、维度**\n",
    "\n",
    "\n",
    "+ 标量\n",
    "+ 向量\n",
    "+ 矩阵\n",
    "+ 立方体\n",
    "+ 多维数组\n",
    "\n",
    "数、列表、numpy的array形式都可以直接作为张量的值。张量的维度其实就是张量的值的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标量\n",
      "维度:()\n",
      "值:1024000\n"
     ]
    }
   ],
   "source": [
    "# 标量，例如机器学习房价预测数据集中一个房子的价格，或者猫狗大战中一个图片的标签。\n",
    "tensor_0 = tf.constant(1024000)\n",
    "print('标量')\n",
    "print('维度:', tensor_0.shape, '\\n', '值:', tensor_0.numpy(), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量\n",
      "维度:(3,)\n",
      "值:[b'cats' b'dogs' b'cats']\n"
     ]
    }
   ],
   "source": [
    "# 向量，例如机器学习房价预测数据集中很多个房子的价格列表，或者猫狗大战中很多图片的标签集合\n",
    "#  或者房价预测数据集中表示一个房子很多属性值的集合\n",
    "tensor_1 = tf.constant(['cats', 'dogs', 'cats'])\n",
    "print('向量')\n",
    "print('维度:', tensor_1.shape, '\\n', '值:', tensor_1.numpy(), sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵\n",
      "维度:(2, 3)\n",
      "值:\n",
      "[[   1 3500    9]\n",
      " [   0 6700   12]]\n"
     ]
    }
   ],
   "source": [
    "# 矩阵, 例如房价预测数据集中表示很多房子属性值组成的矩阵，其中每一行表示一个房子\n",
    "#  或者一个图片单通道的数字矩阵，矩阵的行数和列数就是该图片高度和宽度上的像素数\n",
    "tensor_2 = tf.constant([[1, 3500, 9], [0, 6700, 12]])\n",
    "print('矩阵')\n",
    "print('维度:', tensor_2.shape,  '\\n','值:', '\\n', tensor_2.numpy(), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "立方体\n",
      "维度:(3, 2, 2)\n",
      "值:\n",
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]]\n"
     ]
    }
   ],
   "source": [
    "# 立方体，例如单张图片的三通道的数字矩阵\n",
    "import numpy as np\n",
    "tensor_3 = tf.constant(np.arange(12).reshape(3, 2, 2))\n",
    "print('立方体')\n",
    "print('维度:', tensor_3.shape,  '\\n','值:', '\\n', tensor_3.numpy(), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多维度\n",
      "维度:(4, 3, 2, 2)\n",
      "值:\n",
      "[[[[ 0  1]\n",
      "   [ 2  3]]\n",
      "\n",
      "  [[ 4  5]\n",
      "   [ 6  7]]\n",
      "\n",
      "  [[ 8  9]\n",
      "   [10 11]]]\n",
      "\n",
      "\n",
      " [[[12 13]\n",
      "   [14 15]]\n",
      "\n",
      "  [[16 17]\n",
      "   [18 19]]\n",
      "\n",
      "  [[20 21]\n",
      "   [22 23]]]\n",
      "\n",
      "\n",
      " [[[24 25]\n",
      "   [26 27]]\n",
      "\n",
      "  [[28 29]\n",
      "   [30 31]]\n",
      "\n",
      "  [[32 33]\n",
      "   [34 35]]]\n",
      "\n",
      "\n",
      " [[[36 37]\n",
      "   [38 39]]\n",
      "\n",
      "  [[40 41]\n",
      "   [42 43]]\n",
      "\n",
      "  [[44 45]\n",
      "   [46 47]]]]\n"
     ]
    }
   ],
   "source": [
    "# 4维，例如卷积神经网络模型批量训练时，多张图片的三通道数字矩阵组成的数组\n",
    "import numpy as np\n",
    "tensor_4 = tf.constant(np.arange(48).reshape(4, 3, 2, 2))\n",
    "print('多维度')\n",
    "print('维度:', tensor_4.shape,  '\\n', '值:', '\\n', tensor_4.numpy(), sep='')\n",
    "\n",
    "# 多维度如何看：\n",
    "# 该例子中的值可以看成4个立方体\n",
    "# 每个立方体包括3个矩阵\n",
    "# 每个矩阵是一个2行2列的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、类型**\n",
    "\n",
    "这里的类型指的是张量中值的类型，下面给出所有的数值类型："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **浮点型**\n",
    "    + tf.float16: 16-bit half-precision floating-point. \n",
    "    + tf.float32: 32-bit single-precision floating-point.\n",
    "    + tf.float64: 64-bit double-precision floating-point.\n",
    "    + tf.bfloat16: 16-bit truncated floating-point.\n",
    "+ **复数型**    \n",
    "    + tf.complex64: 64-bit single-precision complex.\n",
    "    + tf.complex128: 128-bit double-precision complex.\n",
    "+ **带符号整型**    \n",
    "    + tf.int8: 8-bit signed integer.\n",
    "    + tf.int16: 16-bit signed integer.\n",
    "    + tf.int32: 32-bit signed integer.\n",
    "    + tf.int64: 64-bit signed integer.\n",
    "+ **无符号整型**    \n",
    "    + tf.uint8: 8-bit unsigned integer.\n",
    "    + tf.uint16: 16-bit unsigned integer.\n",
    "    + tf.uint32: 32-bit unsigned integer.\n",
    "    + tf.uint64: 64-bit unsigned integer.\n",
    "+ **布尔型**\n",
    "    + tf.bool: Boolean.\n",
    "+ **字符串**\n",
    "    + tf.string: String.\n",
    "+ **量化Ops整型**\n",
    "    + tf.qint8: Quantized 8-bit signed integer.\n",
    "    + tf.qint16: Quantized 16-bit signed integer.\n",
    "    + tf.qint32: Quantized 32-bit signed integer.\n",
    "    + tf.quint8: Quantized 8-bit unsigned integer.\n",
    "    + tf.quint16: Quantized 16-bit unsigned integer.\n",
    "+ **可变资源型**    \n",
    "    + tf.resource: Handle to a mutable resource.\n",
    "+ **任意类型**\n",
    "    + tf.variant: Values of arbitrary types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3、值**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 创建值为同一个数\n",
    "    + 全0：**tf.zeros()**\n",
    "    + 全1：**tf.ones()**\n",
    "    + 其他数：**tf.fill()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'v0:0' shape=(3, 4) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全0\n",
    "v0 = tf.Variable(tf.zeros((3, 4)), name='v0')\n",
    "v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'v1:0' shape=(1, 5) dtype=float32, numpy=array([[1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全1\n",
    "v1 = tf.Variable(tf.ones((1, 5)), name='v1')\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([-2, -2, -2, -2])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全为同一个数\n",
    "vs = tf.constant(tf.fill((4, ), -2))\n",
    "vs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 创建值满足已知分布\n",
    "    + 正态分布，**tf.random.normal()**，该分布适用于卷积神经网络中的卷积核参数\n",
    "    + 均匀分布，**tf.random.uniform()**，该分布适用于对抗生成网络中的隐藏参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'vn:0' shape=(4, 2) dtype=float32, numpy=\n",
       "array([[ 1.2010297 ,  0.7132545 ],\n",
       "       [-0.23464002, -1.3844767 ],\n",
       "       [-0.21339473,  0.5485673 ],\n",
       "       [ 0.6425316 , -0.725007  ]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 值服从均值为0，方差为1的标准正态分布\n",
    "vn = tf.Variable(tf.random.normal((4, 2)), name='vn')\n",
    "vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'vn1:0' shape=(2, 6) dtype=float32, numpy=\n",
       "array([[5.1888943, 1.3919209, 1.8373487, 0.5862055, 3.674704 , 5.966487 ],\n",
       "       [3.3122573, 1.2382228, 2.8059695, 5.614332 , 1.3169749, 1.690616 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 值服从均值为mean，方差为stddev的正态分布\n",
    "vn1 = tf.Variable(tf.random.normal((2, 6), mean=3, stddev=2), name='vn1')\n",
    "vn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'va:0' shape=(2, 5) dtype=float32, numpy=\n",
       "array([[0.8165263 , 0.02713096, 0.1222533 , 0.73385644, 0.86358166],\n",
       "       [0.51932955, 0.7474816 , 0.7186899 , 0.6100254 , 0.59229803]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 值服从[0, 1)的均匀分布\n",
    "va = tf.Variable(tf.random.uniform((2, 5)), name='va')\n",
    "va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
       "array([[4.3321157, 2.907641 , 3.8761451, 6.7890377, 6.7365828],\n",
       "       [4.6916285, 7.1469765, 4.3576345, 3.0505333, 2.9605026]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 值服从[minval, maxval)的均匀分布\n",
    "va1 = tf.constant(tf.random.uniform((2, 5), minval=2, maxval=8))\n",
    "va1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([12 13 14 15 16 17 18], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 其他形式的值\n",
    "print(tf.range(12, 19))  # 序列值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 6.  7.  8.  9. 10.], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linspace(6., 10, 5)) # 间隔线性序列值，开始的数必须为为浮点形式\n",
    "# print(tf.linspace(6, 10., 5)) # 报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(4, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "d = tf.constant(tf.random.uniform((4, 3), minval=2, maxval=8))\n",
    "print(tf.zeros_like(d)) # 和张量d具体相同维度的，全是0值\n",
    "print(tf.ones_like(d)) # 和张量d具体相同维度的，全是1值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.9729722  -0.23493397 -1.537703   -0.5289977   1.5097826 ]\n",
      " [ 1.5253828  -1.1116688   0.7487824  -0.10241053 -0.76232475]\n",
      " [-0.7239854  -0.7612631   0.5113612  -0.17950082  1.6409498 ]], shape=(3, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.random.truncated_normal([3, 5], mean=0.0, stddev=1.0)) # 截断正态分布，如果这个数值超过了2个标准差，那么将会被重新随机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.78567111e-03 1.17549435e-38 6.05338812e+00]\n",
      "  [5.90301268e-02 1.17549435e-38 6.39979601e+00]]\n",
      "\n",
      " [[1.82738400e+00 1.17549435e-38 1.13023243e+01]\n",
      "  [5.07768393e-01 1.17549435e-38 1.02421961e+01]]\n",
      "\n",
      " [[2.83003420e-01 1.17549435e-38 8.45455360e+00]\n",
      "  [1.11489305e-02 1.17549435e-38 2.03210716e+01]]], shape=(3, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.random.gamma([3, 2], [0.5, -6, 9])) # Gamma分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.eye(3,3)) #单位矩阵\n",
    "print(tf.linalg.diag([1,2,3])) #对角阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4、变换张量维度**\n",
    "\n",
    "在机器学习模型中，很多情况下会涉及变换维度，下面介绍几种比较常用的导致维度变化的方法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **维度转换：reshape**\n",
    "\n",
    "reshape 就是将原来的数据转换维度，注意前后维度中数字的乘积要保持相同。例如下面示例中的数据的维度为(24,)，维度中数字的乘积为24。因为2\\*12=24，因此该数据可以转换为维度(2, 12)（见data0）；也可以转化为维度(1, 4, 6)（见data1）,因为1\\*4\\*6=24。并且维度转化前后，按照从上到下，从左到右的顺序排列数字，得到的数字序列是不变得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维度: (24,)\n",
      "示例数据:\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n"
     ]
    }
   ],
   "source": [
    "# 示例张量\n",
    "etensor = tf.constant(tf.range(24), dtype=tf.int32)\n",
    "data = etensor.numpy()\n",
    "print('维度:', data.shape)\n",
    "print('示例数据:', data, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2*12=24\n",
    "data0 = data.reshape(2, 12)\n",
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1*4*6=24\n",
    "data1 = data.reshape(1, 4, 6)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7]],\n",
       "\n",
       "       [[ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]],\n",
       "\n",
       "       [[16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1*4*6=3*2*4\n",
    "data2 = data1.reshape(3, 2, 4)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **增加维度：expand_dims**\n",
    "\n",
    "在原数据的axis维度上，增加一个长度为1的维度。注意数据的顺序也没有发生变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "维度: (5,)\n",
      "示例数据:\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# 示例张量\n",
    "etensor1 = tf.constant(tf.range(5), dtype=tf.int32)\n",
    "data1 = etensor1.numpy()\n",
    "print('维度:', data1.shape)\n",
    "print('示例数据:', data1, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[0, 1, 2, 3, 4]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e0 = tf.expand_dims(data1, axis=0)  # 原来的维度为(5,)，在0维度上增加一个长度为1的维度,维度变为(1,5)\n",
    "data_e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int32, numpy=\n",
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e1 = tf.expand_dims(data1, axis=1)  # 原来的维度为(5,)，在1维度上增加一个长度为1的维度,维度变为(5, 1)\n",
    "data_e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1, 1), dtype=int32, numpy=\n",
       "array([[[0]],\n",
       "\n",
       "       [[1]],\n",
       "\n",
       "       [[2]],\n",
       "\n",
       "       [[3]],\n",
       "\n",
       "       [[4]]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_e2 = tf.expand_dims(data1, axis=2)  # 运行错误，因为原来的维度(5,)，没有维度2\n",
    "# data_e2\n",
    "data_e3 = tf.expand_dims(data_e1, axis=2) # 原来的维度为(5,1)，在2维度上增加一个长度为1的维度,维度变为(5, 1, 1)\n",
    "data_e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1.]]], shape=(3, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data_e4 = tf.constant(tf.eye(3,3))\n",
    "data_e5 = tf.expand_dims(data_e4, axis=1)  # 原来的维度为(3, 3)，在1维度上增加一个长度为1的维度(3, 1, 3)\n",
    "print(data_e4, data_e5, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **删除维度：squeeze**\n",
    "\n",
    "注意只能删除长度为1的维度，否则会报错。如果不指定维度参数axis，那么它会默认删除所有长度为1的维度。和增加维度一样，删除维度也不会导致数据序列发生变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e6 = tf.squeeze(data_e5, axis=1) # data_e5维度为(3, 1, 3)，删除1维度上的维度，变为(3, 3)\n",
    "data_e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[10.       10.666667 11.333333 12.      ]], shape=(1, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([10.      , 10.666667, 11.333333, 12.      ], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datarr = tf.constant(tf.linspace(10., 12, 4).numpy().reshape(1, -1))  \n",
    "print(datarr)\n",
    "dataee = tf.squeeze(datarr, axis=0)# datarr维度为(1, 4)，删除0维度上的维度，变为(4,)\n",
    "dataee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[10.      ]\n",
      "   [10.666667]\n",
      "   [11.333333]\n",
      "   [12.      ]]]], shape=(1, 1, 4, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([10.      , 10.666667, 11.333333, 12.      ], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datarr = tf.constant(tf.linspace(10., 12, 4).numpy().reshape(1, 1, -1, 1))  \n",
    "print(datarr)\n",
    "dataee = tf.squeeze(datarr) # 参数axis没有给定值，datarr维度为(1, 1, 4, 1)，删除所有为1的维度，变为(4,)\n",
    "dataee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **维度交换 transpose**\n",
    "\n",
    "前面的操作都不会影响数据序列的变化，而维度交换会导致张量中值的数据序列发生变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.35264185  1.204279   -0.5638717   0.2214014 ]\n",
      " [-1.1977353   0.02041399  1.275478   -1.3119404 ]\n",
      " [ 1.4011785  -0.24270694 -0.45576373 -0.20840964]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 示例\n",
    "data_init = tf.constant(tf.random.normal([3, 4]))\n",
    "print(data_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.35264185  1.204279   -0.5638717   0.2214014 ]\n",
      " [-1.1977353   0.02041399  1.275478   -1.3119404 ]\n",
      " [ 1.4011785  -0.24270694 -0.45576373 -0.20840964]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data_trans = tf.transpose(data_init, perm=[0, 1])  # 和原始数据一样\n",
    "print(data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.35264185 -1.1977353   1.4011785 ]\n",
      " [ 1.204279    0.02041399 -0.24270694]\n",
      " [-0.5638717   1.275478   -0.45576373]\n",
      " [ 0.2214014  -1.3119404  -0.20840964]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data_trans = tf.transpose(data_init, perm=[1, 0])  # 此时perm的意思就是，维度1和维度0互换。维度发生变化，数据序列的顺序也发生了变化。\n",
    "print(data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.2196603  -0.30003804]\n",
      "  [-0.48040333 -0.50385827]\n",
      "  [-1.505559   -1.1153703 ]\n",
      "  [ 0.37644663  0.5113094 ]]\n",
      "\n",
      " [[-0.55146736 -0.5423015 ]\n",
      "  [-0.6172631  -1.2438394 ]\n",
      "  [-1.7114574  -1.1438372 ]\n",
      "  [ 0.14291058  1.7051102 ]]\n",
      "\n",
      " [[ 2.0392156   0.03712146]\n",
      "  [ 1.302432   -0.32173815]\n",
      "  [ 0.41195086 -0.09123792]\n",
      "  [ 0.14018986  0.39686134]]], shape=(3, 4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 1.2196603  -0.48040333 -1.505559    0.37644663]\n",
      "  [-0.55146736 -0.6172631  -1.7114574   0.14291058]\n",
      "  [ 2.0392156   1.302432    0.41195086  0.14018986]]\n",
      "\n",
      " [[-0.30003804 -0.50385827 -1.1153703   0.5113094 ]\n",
      "  [-0.5423015  -1.2438394  -1.1438372   1.7051102 ]\n",
      "  [ 0.03712146 -0.32173815 -0.09123792  0.39686134]]], shape=(2, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "data_init = tf.constant(tf.random.normal([3, 4, 2]))\n",
    "data_trans = tf.transpose(data_init, perm=[2, 0, 1])  # 此时维度变为（2， 3， 4），在实际应用中要注意数据序列是怎么变化的\n",
    "print(data_init, data_trans, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **拼接 concat**\n",
    "\n",
    "\n",
    "拼接操作不会使得拼接后的张量在维度上发生越级的变化，也就是2个值为矩阵的张量拼接的结果不会出现值为立方体的张量。只是在具体的维度数字上发生了变化。 参数axis表示在哪个维度上拼接,拼接后该维度上的数字为2个张量的值的和，此时2个张量其他维度数字必须是相同的。拼接的两个张量的值的类型应该是一致的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的维度：(2,)\n",
      "b的维度：(4,)\n",
      "在维度0上拼接得到\n",
      "tf.Tensor([2. 3. 4. 6. 5. 5.], shape=(6,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([2., 3], dtype=tf.float64)  \n",
    "b = tf.constant([4., 6, 5, 5], dtype=tf.float64)\n",
    "c = tf.concat([a, b], axis=0)  \n",
    "print('a的维度：%s' % a.shape, 'b的维度：%s' % b.shape, '在维度0上拼接得到',c, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的维度：(1, 4)\n",
      "b的维度：(2, 4)\n",
      "在维度0上拼接得到\n",
      "tf.Tensor(\n",
      "[[ 1.  2.  3.  4.]\n",
      " [ 5.  6.  7.  8.]\n",
      " [ 9. 10. 11. 12.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1., 2, 3, 4]])  \n",
    "b = tf.constant([[5., 6, 7, 8], [9, 10, 11, 12]])\n",
    "c = tf.concat([a, b], axis=0) \n",
    "print('a的维度：%s' % a.shape, 'b的维度：%s' % b.shape, '在维度0上拼接得到',c, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的维度：(2, 5)\n",
      "b的维度：(2, 4)\n",
      "在维度1上拼接得到\n",
      "tf.Tensor(\n",
      "[[ 1.  2.  3.  4.  5.  5.  6.  7.  8.]\n",
      " [ 6.  7.  8.  9. 10.  9. 10. 11. 12.]], shape=(2, 9), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1., 2, 3, 4, 5], [6, 7, 8, 9, 10]])  \n",
    "b = tf.constant([[5., 6, 7, 8], [9, 10, 11, 12]])\n",
    "c = tf.concat([a, b], axis=1) \n",
    "print('a的维度：%s' % a.shape, 'b的维度：%s' % b.shape, '在维度1上拼接得到',c, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的维度：(2, 3, 4)\n",
      "b的维度：(2, 2, 4)\n",
      "在维度1上拼接得到\n",
      "tf.Tensor(\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [ 0  1  2  3]\n",
      "  [ 4  5  6  7]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]]], shape=(2, 5, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(tf.range(24).numpy().reshape(2, 3, 4))  \n",
    "b = tf.constant(tf.range(16).numpy().reshape(2, 2, 4))\n",
    "c = tf.concat([a, b], axis=1) \n",
    "print('a的维度：%s' % a.shape, 'b的维度：%s' % b.shape, '在维度1上拼接得到',c, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **堆叠 stack**\n",
    "\n",
    "和拼接不同，堆叠会导致维度发生越级。其中axis默认为0，堆叠必须保证2个张量的维度是一致的，也就是可以在越级后的任意维度上实现堆叠。需要注意观察在某个维度上是如何完成堆叠的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x的维度：(2, 3)\n",
      "y的维度：(2, 3)\n",
      "在维度1上堆叠得到\n",
      "tf.Tensor(\n",
      "[[[2. 4.]\n",
      "  [3. 6.]\n",
      "  [4. 4.]]\n",
      "\n",
      " [[4. 5.]\n",
      "  [5. 6.]\n",
      "  [4. 0.]]], shape=(2, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[2., 3, 4], [4, 5, 4]])  \n",
    "y = tf.constant([[4., 6, 4], [5, 6, 0]])\n",
    "z = tf.stack([x, y], axis=2)  \n",
    "print('x的维度：%s' % x.shape, 'y的维度：%s' % y.shape, '在维度1上堆叠得到',z, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x的维度：(5, 3, 4) y的维度：(5, 3, 4) 升级后的维度形式为(axis0,, axis1, axis2, axis3)\n",
      "在维度0上堆叠得到：(2, 5, 3, 4)\n",
      "在维度1上堆叠得到：(5, 2, 3, 4)\n",
      "在维度2上堆叠得到：(5, 3, 2, 4)\n",
      "在维度3上堆叠得到：(5, 3, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(tf.range(60).numpy().reshape(5, 3, 4))  \n",
    "y = tf.constant(tf.range(100, 160).numpy().reshape(5, 3, 4))\n",
    "print('x的维度：%s' % x.shape, 'y的维度：%s' % y.shape, '升级后的维度形式为(axis0,, axis1, axis2, axis3)')\n",
    "for i in range(4):\n",
    "    z = tf.stack([x, y], axis=i) \n",
    "    print('在维度%d上堆叠得到：%s' % (i, z.shape), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **分割 split**\n",
    "\n",
    "tf.split(x, axis, num_or_size_splits)可以完成张量的分割操作，返回的是列表形式。其中\n",
    "+ x：待分割张量\n",
    "+ axis：分割的维度索引号\n",
    "+ num_or_size_splits：切割方案。当num_or_size_splits 为单个数值时，如6，表示切割为6份；当分割的那个维度数值不能被该数字整除时会报错；当num_or_size_splits 为List 时，每个元素表示每份的长度，如[2, 1, 1, 2]表示切割为4 份，每份的长度分别为2,1,1,2。\n",
    "\n",
    "该操作可用于机器学习中数据集的划分，划分为训练数据集、测试数据集、验证数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[<tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
      "array([[[ 0.03337711,  0.18521185],\n",
      "        [-1.1947967 ,  1.1517807 ],\n",
      "        [-0.9532431 , -0.08698589]]], dtype=float32)>, <tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
      "array([[[ 1.9886509 , -0.40439484],\n",
      "        [ 0.75066054,  0.39359376],\n",
      "        [ 0.1842478 , -0.43016267]]], dtype=float32)>, <tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
      "array([[[ 0.9229125 ,  1.185722  ],\n",
      "        [ 1.0482429 , -1.4969912 ],\n",
      "        [-1.5678961 , -0.56533664]]], dtype=float32)>, <tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
      "array([[[-1.979329  ,  0.03433766],\n",
      "        [ 0.327534  ,  0.47513118],\n",
      "        [-0.82707894,  1.5447776 ]]], dtype=float32)>, <tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
      "array([[[-0.28827646, -0.3962664 ],\n",
      "        [-0.89006174, -1.3457936 ],\n",
      "        [ 0.21801203, -0.6118329 ]]], dtype=float32)>, <tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n",
      "array([[[-0.31167012,  0.3854084 ],\n",
      "        [-0.03056858,  0.24651845],\n",
      "        [ 1.3114127 ,  0.9813252 ]]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([6, 3, 2])\n",
    "y = tf.split(x,axis=0,num_or_size_splits=6)\n",
    "print(type(y))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.03337711  0.18521185]\n",
      "  [-1.1947967   1.1517807 ]]\n",
      "\n",
      " [[ 1.9886509  -0.40439484]\n",
      "  [ 0.75066054  0.39359376]]\n",
      "\n",
      " [[ 0.9229125   1.185722  ]\n",
      "  [ 1.0482429  -1.4969912 ]]\n",
      "\n",
      " [[-1.979329    0.03433766]\n",
      "  [ 0.327534    0.47513118]]\n",
      "\n",
      " [[-0.28827646 -0.3962664 ]\n",
      "  [-0.89006174 -1.3457936 ]]\n",
      "\n",
      " [[-0.31167012  0.3854084 ]\n",
      "  [-0.03056858  0.24651845]]], shape=(6, 2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.9532431  -0.08698589]]\n",
      "\n",
      " [[ 0.1842478  -0.43016267]]\n",
      "\n",
      " [[-1.5678961  -0.56533664]]\n",
      "\n",
      " [[-0.82707894  1.5447776 ]]\n",
      "\n",
      " [[ 0.21801203 -0.6118329 ]]\n",
      "\n",
      " [[ 1.3114127   0.9813252 ]]], shape=(6, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y = tf.split(x,axis=1,num_or_size_splits=[2, 1]) # 维度1上数字为3，所以可以划分为2和1的2份。\n",
    "for k in y:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **分解 unstack**\n",
    "\n",
    "直接在axis上全部按长度为1的方式分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.93870497 -0.16704509  0.0116909   0.7145192  -0.6210658   1.2631401 ], shape=(6,), dtype=float32)\n",
      "tf.Tensor([ 0.0772516   0.12491262 -0.05570203 -1.7422643   1.0625361   1.0719345 ], shape=(6,), dtype=float32)\n",
      "tf.Tensor([ 0.69672793 -2.432379    1.0710338  -0.20531014 -1.544502   -0.5648942 ], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([6, 3])\n",
    "y = tf.unstack(x,axis=1)\n",
    "for k in y:\n",
    "    print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
